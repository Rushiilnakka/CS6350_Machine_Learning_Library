{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "198300e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39599840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#column_headers = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'label']\n",
    "df1=pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-4\\\\train.csv\")\n",
    "X_train = df1.drop('y', axis=1)\n",
    "y_train = df1['y']\n",
    "\n",
    "df2 = pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-4\\\\test.csv\")\n",
    "X_test = df2.drop('y', axis=1)\n",
    "y_test = df2['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74a2f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, attribute, attributeName, is_leaf, label, depth, info_gain, entropy_parent_attr, parent_attr_val):\n",
    "        self.attribute = attribute\n",
    "        self.attributeName = attributeName\n",
    "        self.children = {}\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.depth = depth\n",
    "        self.info_gain = info_gain\n",
    "        self.entropy_parent_attr = entropy_parent_attr\n",
    "        self.parent_attr_val = parent_attr_val\n",
    "\n",
    "    def get_attribute(self):\n",
    "        return self.attribute\n",
    "\n",
    "    def add_child(self, child_node, attr_value):\n",
    "        self.children[attr_value] = child_node\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.label\n",
    "        current_val = x[self.attribute]\n",
    "        if current_val not in self.children.keys():\n",
    "            return self.label\n",
    "        return self.children[current_val].predict(x)\n",
    "\n",
    "    def print_node(self, space=\"\"):\n",
    "        print(f\"{space}Depth: {self.depth}\")\n",
    "        print(f\"{space}Selected Feature: {self.attributeName}\")\n",
    "        print(f\"{space}Information Gain for Parent Feature: {self.info_gain}\")\n",
    "        print(f\"{space}Entropy for Parent Feature: {self.entropy_parent_attr}\")\n",
    "        print(f\"{space}Parent Feature Value: {self.parent_attr_val}\")\n",
    "        print(f\"{space}Label: {self.label}\")\n",
    "        for child in self.children.values():\n",
    "            child.print_node(space + \"\\t\")\n",
    "\n",
    "    def _majority_error(self, X, y, attribute):\n",
    "        values = set(X[attribute])\n",
    "        return sum([(X[attribute] == value).mean() *\n",
    "            (1 - Counter(y[X[attribute] == value]).most_common(1)[0][1] / len(y[X[attribute] == value]))\n",
    "                    for value in values])\n",
    "\n",
    "    def _gini(self, X, y, attribute):\n",
    "        values = set(X[attribute])\n",
    "        gini = 1\n",
    "        for value in values:\n",
    "            p = (X[attribute] == value).mean()\n",
    "            gini -= p**2\n",
    "        return gini\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=np.inf):\n",
    "        self.root = None\n",
    "        self.depth = 0\n",
    "        if max_depth < 1:\n",
    "            print(\"max_depth cannot be lower than 1! Setting it to 1.\")\n",
    "            max_depth = 1\n",
    "        self.max_depth = max_depth\n",
    "        self.longest_path_len = 0\n",
    "\n",
    "    def build_tree(self, X, Y, attribute_names, attribute_list=[], current_depth=0,\n",
    "                   parent_info={\"max_info_gain\": None, \"attribute_list[max_attribute]\": None, \"value\": None}):\n",
    "        if current_depth > self.longest_path_len:\n",
    "            self.longest_path_len = current_depth\n",
    "        if current_depth >= self.max_depth or len(attribute_list) == 0 or len(np.unique(Y)) == 1:\n",
    "            vals, counts = np.unique(Y, return_counts=True)\n",
    "            return TreeNode(None, None, True, vals[np.argmax(counts)], current_depth,\n",
    "                            parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                            parent_info[\"value\"])\n",
    "\n",
    "        max_info_gain = -1\n",
    "        max_attribute = None\n",
    "        i = 0\n",
    "        for attribute in attribute_list:\n",
    "            info_gain, entropy_attribute, entropy_parent = self.calculate_information_gain(X, Y, attribute)\n",
    "            if info_gain > max_info_gain:\n",
    "                max_info_gain = info_gain\n",
    "                max_attribute = i\n",
    "                entropy = entropy_parent\n",
    "            i += 1\n",
    "\n",
    "        vals, counts = np.unique(Y, return_counts=True)\n",
    "        root = TreeNode(attribute_list[max_attribute], attribute_names[attribute_list[max_attribute]],\n",
    "                        False, vals[np.argmax(counts)], current_depth,\n",
    "                        parent_info[\"max_info_gain\"], parent_info[\"attribute_list[max_attribute]\"],\n",
    "                        parent_info[\"value\"])\n",
    "\n",
    "        attribute_values = np.unique(X[:, attribute_list[max_attribute]])\n",
    "        new_attribute_list = np.delete(attribute_list, max_attribute)\n",
    "        for value in attribute_values:\n",
    "            indices = np.where(X[:, attribute_list[max_attribute]] == value)[0]\n",
    "            if len(indices) == 0:\n",
    "                root.add_child(TreeNode(None, None, True, vals[np.argmax(counts)], current_depth + 1,\n",
    "                                        max_info_gain, attribute_list[max_attribute], value), current_depth)\n",
    "            else:\n",
    "                parent_info = {\n",
    "                    \"max_info_gain\": max_info_gain,\n",
    "                    \"attribute_list[max_attribute]\": entropy,\n",
    "                    \"value\": value\n",
    "                }\n",
    "                root.add_child(self.build_tree(X[indices], Y[indices], attribute_names, new_attribute_list,\n",
    "                                               current_depth + 1, parent_info), value)\n",
    "        return root\n",
    "\n",
    "    def calculate_entropy(self, counts):\n",
    "        total = sum(counts)\n",
    "        entropy_value = 0\n",
    "        for element in counts:\n",
    "            p = (element / total)\n",
    "            if p != 0:\n",
    "                entropy_value -= p * np.log2(p)\n",
    "        return entropy_value\n",
    "\n",
    "    def calculate_information_gain(self, X, Y, attribute):\n",
    "        _, counts = np.unique(Y, return_counts=True)\n",
    "        entropy_attribute = self.calculate_entropy(counts)\n",
    "        entropy_parent = 0\n",
    "        distinct_attr_values = list(set(X[:, attribute]))\n",
    "        for val in distinct_attr_values:\n",
    "            indices = np.where(X[:, attribute] == val)[0]\n",
    "            _, counts = np.unique(Y[indices], return_counts=True)\n",
    "            entr = self.calculate_entropy(counts)\n",
    "            entropy_parent += (len(indices) / len(Y)) * entr\n",
    "        info_gain = entropy_attribute - entropy_parent\n",
    "        return info_gain, entropy_attribute, entropy_parent\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        attribute_names = list(range(X.shape[1]))  # Assume attributes are indexed\n",
    "        attribute_list = np.arange(X.shape[1])\n",
    "        self.root = self.build_tree(X, Y, attribute_names, attribute_list, 0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(X.shape[0]):\n",
    "            predictions.append(self.root.predict(X[i]))\n",
    "        return predictions\n",
    "\n",
    "    def get_longest_path_len(self):\n",
    "        return self.longest_path_len\n",
    "\n",
    "    def get_root_attribute(self):\n",
    "        if self.root:\n",
    "            return self.root.get_attribute()\n",
    "        return None\n",
    "\n",
    "    def print_tree(self):\n",
    "        self.root.print_node(\"\")\n",
    "        \n",
    "class BaggedTreesClassifier:\n",
    "    def __init__(self, num_trees):\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        for _ in range(self.num_trees):\n",
    "            # Create a bootstrap sample\n",
    "            indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_bootstrap, y_bootstrap = X[indices], y[indices]\n",
    "\n",
    "            # Train a decision tree on the bootstrap sample\n",
    "            dt_classifier = DecisionTreeClassifier(max_depth=np.inf)\n",
    "            dt_classifier.fit(X_bootstrap, y_bootstrap)\n",
    "            self.trees.append(dt_classifier)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += tree.predict(X)\n",
    "        return np.sign(predictions)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-4\\\\train.csv\")\n",
    "X_train = train_df.drop('y', axis=1).values\n",
    "y_train = train_df['y'].apply(lambda x: 1 if x == 'yes' else 0).values.astype(float)\n",
    "\n",
    "test_df = pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-4\\\\test.csv\")\n",
    "X_test = test_df.drop('y', axis=1).values\n",
    "y_test = test_df['y'].apply(lambda x: 1 if x == 'yes' else 0).values.astype(float)\n",
    "\n",
    "# Vary the number of trees from 1 to 500\n",
    "num_trees_range = range(1, 500)\n",
    "train_errors_bagging = []\n",
    "test_errors_bagging = []\n",
    "\n",
    "for num_trees in num_trees_range:\n",
    "    # Create and fit the Bagged Trees classifier\n",
    "    bagged_trees_classifier = BaggedTreesClassifier(num_trees)\n",
    "    bagged_trees_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the trained classifier\n",
    "    y_train_pred = bagged_trees_classifier.predict(X_train)\n",
    "    y_test_pred = bagged_trees_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate training and test errors\n",
    "    train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "    test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    train_errors_bagging.append(train_error)\n",
    "    test_errors_bagging.append(test_error)\n",
    "\n",
    "# Plotting the errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(num_trees_range, train_errors_bagging, label='Train Error (Bagging)')\n",
    "plt.plot(num_trees_range, test_errors_bagging, label='Test Error (Bagging)')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Training and Test Errors vs. Number of Trees (Bagging)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
