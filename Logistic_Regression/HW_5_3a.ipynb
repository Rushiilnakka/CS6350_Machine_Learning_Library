{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3da22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 0.01, Training Error: 0.6911216652931447, Test Error: 0.6910101443877223\n",
      "Variance: 0.1, Training Error: 0.6756709759280292, Test Error: 0.6748002728689408\n",
      "Variance: 0.5, Training Error: 0.6205629654896515, Test Error: 0.617284684664134\n",
      "Variance: 1, Training Error: 0.57203131500049, Test Error: 0.5671051054287635\n",
      "Variance: 3, Training Error: 0.4644027219464454, Test Error: 0.4579856099990604\n",
      "Variance: 5, Training Error: 0.4065635568827452, Test Error: 0.400691056084308\n",
      "Variance: 10, Training Error: 0.32697634883865523, Test Error: 0.3230672405311573\n",
      "Variance: 100, Training Error: 0.1624926191167526, Test Error: 0.16388617419848844\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the training dataset\n",
    "def load_train_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-note-1\\\\bank-note\\\\train.csv\")\n",
    "\n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Load the test dataset\n",
    "def load_test_data():\n",
    "    \n",
    "    data = pd.read_csv(\"C:\\\\Rushiil\\\\ML\\\\bank-note-1\\\\bank-note\\\\test.csv\")\n",
    "\n",
    "    # Assuming the last column is the target variable\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Logistic Regression functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_error(X, y, w):\n",
    "    # Compute the logistic regression error\n",
    "    y_pred = sigmoid(np.dot(X, w))\n",
    "    error = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    return error\n",
    "\n",
    "# Main logistic regression with MAP estimation\n",
    "def logistic_regression_MAP(X_train, y_train, X_test, y_test, prior_variance):\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize parameters\n",
    "    num_epochs = 100\n",
    "    w = np.zeros(X_train.shape[1])\n",
    "\n",
    "    # Learning rate schedule parameters\n",
    "    gamma0 = 0.01\n",
    "    d = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = np.random.permutation(len(y_train))\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train[permutation]\n",
    "\n",
    "        for t, (x_n, y_n) in enumerate(zip(X_train_shuffled, y_train_shuffled)):\n",
    "            # Compute sigmoid\n",
    "            sigmoid_value = sigmoid(np.dot(w, x_n))\n",
    "\n",
    "            # Compute gradient\n",
    "            gradient = -(y_n - sigmoid_value) * x_n + (1 / prior_variance) * w\n",
    "\n",
    "            # Update learning rate\n",
    "            learning_rate = gamma0 / (1 + (gamma0 / d) * (epoch * len(y_train) + t))\n",
    "\n",
    "            # Update weights\n",
    "            w -= learning_rate * gradient\n",
    "\n",
    "    # Evaluate on training and test sets\n",
    "    train_error = compute_error(X_train, y_train, w)\n",
    "    test_error = compute_error(X_test, y_test, w)\n",
    "\n",
    "    return train_error, test_error\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Load training data\n",
    "    X_train, y_train = load_train_data()\n",
    "\n",
    "    # Load test data\n",
    "    X_test, y_test = load_test_data()\n",
    "\n",
    "    # Prior variances to test\n",
    "    prior_variances = [0.01, 0.1, 0.5, 1, 3, 5, 10, 100]\n",
    "\n",
    "    # Perform logistic regression for each prior variance\n",
    "    for prior_variance in prior_variances:\n",
    "        train_error, test_error = logistic_regression_MAP(X_train, y_train, X_test, y_test, prior_variance)\n",
    "        print(f\"Variance: {prior_variance}, Training Error: {train_error}, Test Error: {test_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0789076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
