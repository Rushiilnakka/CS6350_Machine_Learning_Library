# Linear Regression
This implements a batch gradient, stochastic gradient descent, calculate the optimal weight vector.
# Commands
To run the batch gradient descent algorithm on concrete dataset:
python3 (HW_2_4a.ipynb, 

To run the stochastic gradient descent (SGD) algorithm on concrete dataset:
python3 HW_2_4b_4c.ipynb, 

To run the calculate the optimal weight vector on concrete dataset:
python3 HW_2_4b_4c.ipynb

#In question 4a,4b,4c (HW_2_4a.ipynb, HW_2_4b_4c.ipynb, HW_2_4b_4c.ipynb)

The dataset location has to be updated, as the location given is the local folder location. Here bank dataset has to be used.
# Load data
train_df = pd.read_csv("C:\\Rushiil\\ML\\concrete\\train.csv")
test_df = pd.read_csv("C:\\Rushiil\\ML\\concrete\\test.csv")


# Ensemble Learning
This implements a adaboost, bagged trees, randam forest.
# Commands
To run the adaboost algorithm on bank dataset:
python3 HW_2_2a.ipynb

To run the bagged trees algorithm on bank dataset:
python3 HW_2_2b.ipynb

To run the bias and variance decomposition on bank dataset:
python3 HW_2_2b.ipynb

To run the random forest algorithm on bank dataset:
python3 2d.ipynb

To run the bias and variance decomposition, squared error on bank dataset:
python3 HW_2_2b.ipynb

#In question 2a,2b,2c,2d,2e (HW_2_2a.ipynb, HW_2_2b.ipynb, HW_2_2b.ipynb, 2d.ipynb,HW_2_2b.ipynb)

The dataset location has to be updated, as the location given is the local folder location. Here bank dataset has to be used.
# Load data
train_df = pd.read_csv("C:\\Rushiil\\ML\\bank-4\\train.csv")
test_df = pd.read_csv("C:\\Rushiil\\ML\\bank-4\\test.csv")







